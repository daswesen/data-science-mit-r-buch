---
title: "R Notebook"
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(pROC)
```


```{r}
titanic <- read_delim("data/titanic.csv", delim = ";", 
    escape_double = FALSE, trim_ws = TRUE)
```

Eine andere Möglichkeit, Dummy-Variablen zu erstellen, bietet das Caret-Package. Der Parameter fullRank sorgt dafür, dass wir Anzahl Merkmalsausprägungen - 1 erzeugen:

```{r}

dmy <- dummyVars(" ~ sex", data = titanic, fullRank=T)
trsf <- data.frame(predict(dmy, newdata = titanic))
print(trsf)
```
```{r}
titanic_subset <- titanic %>%
  select(survived,pclass,age) %>%
  mutate(age = str_replace(age,",",".")) %>%
  mutate(age = as.double(age)) %>%
  mutate(survived = as.factor(survived))
titanic_subset <- cbind(titanic_subset,trsf)
titanic_subset <- titanic_subset %>%
  filter(!is.na(age))
```


Der Datensatz wird in Trainings- und Test-Daten geteilt. Hierfür verwenden wir wieder die Library Caret, denn wir wollen, dass in unseren Samples das Feature "Survived" gleichmäßig ausgeprägt ist.

```{r}
set.seed(456)
trainIndex=createDataPartition(titanic_subset$survived, p=0.8)$Resample1
train.data=titanic_subset[trainIndex, ]
test.data=titanic_subset[-trainIndex, ]
```

```{r}
table(titanic$survived,titanic$sex)
```

```{r}
table(train.data$survived,train.data$sex)
```

## Decision Tree
```{r}
library(rpart)
library(rpart.plot)
tree<- rpart(survived~., data = train.data, method = 'class')
rpart.plot(tree)
```
```{r}
dt_results <- predict(tree, test.data[,-1], type = 'prob')
head(model.results.dt <- cbind(test.data,dt_results))
```
```{r}
test.results <- model.results.dt %>%
  mutate(pred = ifelse(`1`>=0.5,1,0))
table(test.results$pred, test.data$survived)
```

library(pROC)
pROC_obj <- roc(as.numeric(test.data$survived), probs,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")

```{r warning=FALSE}
pROC_obj <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")
```



## Support Vector Machines
Für die Klassifikation wird das Package e1071 verwendet:

```{r}
library(e1071)
cbind(train.data[,1],scale(train.data[,2:4]))
classifier = svm(survived ~ .,
                 data = train.data,
                 type = 'C-classification',
                 probability = TRUE,
                 kernel = 'linear')
```

Wir nehmen die Test-Daten...

```{r}
library(scatterplot3d)
colors <- c("#000000", "#C0C0C0")
colors <- colors[as.numeric(train.data$survived)]
scatterplot3d(train.data[,-1], color=colors)
```





```{r}
# Predicting the Validation set results
svm.predict = predict(classifier, newdata = test.data[,-1], probability = TRUE)
```

...und werfen das entstandene Modell auf die Test-Daten:

```{r}
# Checking the prediction accuracy
table(test.data$survived, svm.predict) # Confusion matrix
```

Nun rechnen wir wieder die Genauigkeit aus:

```{r}
error <- mean(test.data$survived != svm.predict) # Misclassification error
paste('Accuracy',round(1-error,4))
```

```{r}
head(cbind(test.data,svm.predict), 10)
```

```{r}
probs <- attr(svm.predict, "prob")[,2]
```

```{r}
probs <- attr(svm.predict, "prob")[,2]
pROC_obj <- roc(as.numeric(test.data$survived), probs,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")
```

Wirklich gut sieht dies noch nicht aus.

Hier noch ein Beispiel für einen anderen Kernel, eine nicht-lineare Support Vector Machine:

```{r}

classifier = svm(survived ~ .,
                 data = train.data,
                 type = 'C-classification',
                 probability = TRUE,
                 kernel = 'radial')

svm.nlm.predict = predict(classifier, newdata = test.data[,-1], , probability = TRUE)


table(test.data$survived, svm.nlm.predict) 

error <- mean(test.data$Survived != svm.nlm.predict) 
paste('Accuracy',round(1-error,4))
```

```{r}
probs <- attr(svm.nlm.predict, "prob")[,2]
```

```{r}
library(pROC)
pROC_obj <- roc(as.numeric(test.data$survived), probs,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")
```



## Naive Bayes

```{r}
train.data.nb <- train.data %>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(age = as.factor(if_else(age > 14, "adult", "child"))) 

test.data.nb <- test.data %>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(age = as.factor(if_else(age > 14, "adult", "child")))
```


Die Library e1071 kann auch für NaiveBayes verwendet werden, das Trainieren startet wieder mit einem einfachen Befehl:

```{r}
Naive_Bayes_Model=naiveBayes(survived ~., data=train.data.nb, type = "raw")
Naive_Bayes_Model
```

Nun wird das Modell auf die Test-Daten "geworfen":

```{r}
Titanic.class <- predict(Naive_Bayes_Model, test.data.nb[,-1])
table(Titanic.class, test.data.nb$survived)
```


```{r}
prop.table(table(Titanic.class))
```

Nun schauen wir uns die Genauigkeit unseres Modells an:




Mit cbind können wir uns die Prediction zusammen mit den Originaldaten sehen und somit sehen, wo der Algorithmus richtig und wo er falsch gelegen hat.

```{r}
head(model.results <- cbind(test.data.nb,Titanic.class),20)
```

Auch kann für jedes Segment überprüft werden, wie gut der Klassifikator gearbeitet hat.

```{r}
#table(as.data.frame(Titanic.class), test.data.nb$Class)
```





```{r message=FALSE, warning=FALSE, echo=FALSE}
Titanic.class <- predict(Naive_Bayes_Model, test.data.nb[,-1], type = "raw")
titanic.probs <- Titanic.class[,2]
pROC_obj <- roc(as.numeric(model.results$survived), titanic.probs,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")
```
Dies geht langsam in die richtige Richtung :)



## XG Boost

```{r}
library(xgboost)
```



```{r}
dtrain <- as.matrix(train.data[,-1])
mode(dtrain) <- 'double'
```

```{r}
train.data.xg <- train.data %>%
  mutate(survived = as.integer(if_else(survived == "0",0,1)))
```


```{r}
xgb <- xgboost(
  dtrain, 
  label = train.data.xg$survived, 
  nrounds=100, 
  max_depth = 10, eta = 0.1, verbose = 0, nthread = 8, objective = "binary:logistic"
)
```


```{r}
xg_matrix <- as.matrix(test.data[,-1])
pred <- predict(xgb, xg_matrix)
print(head(pred))
```

```{r}
xgb.df <- as.data.frame(pred)
head(results.xg2 <- cbind(xgb.df,test.data))
```

```{r}
xgb2 <- xgboost(
  dtrain, 
  label = train.data.xg$survived, 
  nrounds=100, 
  max_depth = 10, eta = 0.1, verbose = 0, nthread = 8, objective = "binary:hinge"
)
pred2 <- predict(xgb2, xg_matrix)
confusionMatrix(as.factor(pred2),factor(test.data$survived))

```


```{r warning=FALSE, message=FALSE}
pROC_obj <- roc(results.xg2$survived,results.xg2$pred,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)


sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")
```
```{r}
mat <- xgb.importance (feature_names = colnames(train.data.xg[,-1]),model = xgb)
xgb.plot.importance (importance_matrix = mat[1:10]) 
```


## Klassifikation von Mails in Ham und Spam

Wer es noch nicht wusste, der Grund dafür, dass wir unerwünschte Werbe-Emails als Spam bezeichnen, ist ein alter Monty Python-Sketch. Das folgende Beispiel ist inspiriert von [Harshit Kumar](https://kharshit.github.io/blog/2017/08/25/email-spam-filtering-text-analysis-in-r).

```{r}
emails = read.csv('data/emails.csv', stringsAsFactors = FALSE)
table(emails$spam)
```

Wir nutzen zwei Libraries, tm, das für Text Mining verwendet wird, und SnowballC, ein Stemmer. Damit bilden wir einen Corpus:

```{r}
library(tm)
library(SnowballC)
corpus = VCorpus(VectorSource(emails$text))
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("en"))
corpus = tm_map(corpus, stemDocument)
```

Als nächstes wird eine Document Term Matrix gebildet:

```{r}
dtm = DocumentTermMatrix(corpus)
dtm
```

Daraus werden nur die häufigsten Terme verwendet:

```{r}
spdtm = removeSparseTerms(dtm, 0.95)
spdtm
```

Daraus wird ein Data Frame erstellt:

```{r}
emailsSparse = as.data.frame(as.matrix(spdtm))
colnames(emailsSparse) = make.names(colnames(emailsSparse))
emailsSparse$spam = emails$spam
emailsSparse$spam = as.factor(emailsSparse$spam)
```

Nun wird wie gehabt der Corpus geteilt in Training und Test:
```{r}
set.seed(983)
trainIndex=createDataPartition(emailsSparse$spam, p=0.8)$Resample1
train.data=emailsSparse[trainIndex, ]
test.data=emailsSparse[-trainIndex, ]
```

Es wird ein Naive Bayes-Modell gebildet:

```{r}
Naive_Bayes_Model=naiveBayes(spam ~., data=train.data, type = "raw")
```

```{r}
Spam.class <- predict(Naive_Bayes_Model, test.data)
table(Spam.class, test.data$spam)
```



```{r}
model.results <- cbind(test.data,Spam.class)
```

```{r}
Spam.class <- predict(Naive_Bayes_Model, test.data, type = "raw")
real_spam <- as.numeric(as.character(model.results$spam))
```



```{r warning=FALSE, message=FALSE}

pROC_obj <- roc(real_spam, Spam.class[,2],
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
plot(sens.ci, type="bars")
```


```{r}
Naive_Bayes_Model
```

